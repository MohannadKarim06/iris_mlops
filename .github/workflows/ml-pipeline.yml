name: Complete MLOps Pipeline

on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      destroy_infrastructure:
        description: 'Destroy infrastructure after deployment (for testing)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'

env:
  AWS_REGION: eu-north-1
  EKS_CLUSTER: iris-mlops-cluster
  TF_VAR_region: eu-north-1

jobs:
  infrastructure:
    runs-on: ubuntu-latest
    outputs:
      cluster_endpoint: ${{ steps.terraform.outputs.cluster_endpoint }}
      ecr_repository_url: ${{ steps.terraform.outputs.ecr_repository_url }}
      cluster_name: ${{ steps.terraform.outputs.cluster_name }}
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.6.0
        terraform_wrapper: false
    
    - name: Terraform Init
      run: |
        cd terraform-scripts
        terraform init
    
    - name: Terraform Plan
      run: |
        cd terraform-scripts
        terraform plan -out=tfplan
    
    - name: Terraform Apply
      id: terraform
      run: |
        cd terraform-scripts
        terraform apply -auto-approve tfplan
        
        # Capture outputs
        echo "cluster_endpoint=$(terraform output -raw cluster_endpoint)" >> $GITHUB_OUTPUT
        echo "ecr_repository_url=$(terraform output -raw ecr_repository_url)" >> $GITHUB_OUTPUT
        echo "cluster_name=$(terraform output -raw cluster_name)" >> $GITHUB_OUTPUT
    
    - name: Wait for EKS cluster to be ready
      run: |
        echo "Waiting for EKS cluster to be fully ready..."
        aws eks wait cluster-active --name ${{ env.EKS_CLUSTER }} --region ${{ env.AWS_REGION }}
        
        echo "Waiting for node group to be ready..."
        aws eks wait nodegroup-active --cluster-name ${{ env.EKS_CLUSTER }} --nodegroup-name iris-nodes --region ${{ env.AWS_REGION }}
        
        echo "Infrastructure is ready!"

  build-and-deploy:
    needs: infrastructure
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.8'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Initialize DVC
      run: |
        dvc init --no-scm || echo "DVC is already initialized"

    - name: Run ML Pipeline 
      run: |
        dvc repro
    
    - name: Build BentoML Service
      run: |
        # Build models first
        python scripts/build_bento.py
        
        # Navigate to bentoml directory
        cd bentoml
        
        # Copy required files
        cp ../requirements.txt .
        mkdir -p models
        cp -r ../models/* models/
        
        # Build only (no containerize)
        echo "Building BentoML service..."
        bentoml build
        
        cd ..

    - name: Build Custom Docker Image
      run: |
        # Copy Dockerfile to bentoml directory
        cp Dockerfile bentoml/
        
        # Build Docker image using our custom Dockerfile
        cd bentoml
        docker build -t iris_classifier_service:latest .
        
        # Tag the image for ECR
        docker tag iris_classifier_service:latest iris_classifier_service:${{ github.sha }}
        
        echo "Docker image built successfully"
        docker images | grep iris_classifier_service

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Login to ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1
    
    - name: Build and push Docker image
      run: |
        # Use the ECR URL from infrastructure job
        ECR_URI="${{ needs.infrastructure.outputs.ecr_repository_url }}"
        docker tag iris_classifier_service:latest $ECR_URI:${{ github.sha }}
        docker tag iris_classifier_service:latest $ECR_URI:latest
        
        # Push to ECR
        docker push $ECR_URI:${{ github.sha }}
        docker push $ECR_URI:latest
        
        echo "ECR_URI=$ECR_URI" >> $GITHUB_ENV
    
    - name: Install and Configure kubectl
      run: |
        # Install kubectl
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/
        
        # Configure kubectl - this should work since we're the cluster creator
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER }}
        
        # Test connection
        kubectl get nodes
        
        echo "âœ… kubectl configured successfully"
    
    - name: Deploy to EKS
      run: |
        # Create AWS secret for MLflow
        kubectl create secret generic aws-secret \
          --from-literal=access-key-id=${{ secrets.AWS_ACCESS_KEY_ID }} \
          --from-literal=secret-access-key=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
          --dry-run=client -o yaml | kubectl apply -f -
        
        # Update image in deployment
        export ECR_IMAGE="${{ env.ECR_URI }}:${{ github.sha }}"
        export ECR_REGISTRY="${{ steps.login-ecr.outputs.registry }}"
        export IMAGE_TAG="${{ github.sha }}"
        envsubst < k8s/iris-service.yaml | kubectl apply -f -
        
        # Deploy other services
        kubectl apply -f k8s/prometheus.yaml
        kubectl apply -f k8s/grafana.yaml
        kubectl apply -f k8s/mlflow.yaml
        kubectl apply -f k8s/streamlit.yaml
        
        # Wait for deployment
        kubectl rollout status deployment/iris-service --timeout=600s
        
        echo "âœ… Deployment completed"
    
    - name: Install AWS Load Balancer Controller
      run: |
        # Install ALB controller CRDs
        kubectl apply -k "github.com/aws/eks-charts/stable/aws-load-balancer-controller//crds?ref=master"
        
        # Get account ID and update the ALB controller YAML
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        
        # Create service account for ALB controller
        cat <<EOF | kubectl apply -f -
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          labels:
            app.kubernetes.io/component: controller
            app.kubernetes.io/name: aws-load-balancer-controller
          name: aws-load-balancer-controller
          namespace: kube-system
          annotations:
            eks.amazonaws.com/role-arn: arn:aws:iam::${ACCOUNT_ID}:role/AmazonEKSLoadBalancerControllerRole
        EOF
        
        # Install ALB controller using Helm
        curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
        chmod 700 get_helm.sh
        ./get_helm.sh
        
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update
        
        helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          --set clusterName=${{ env.EKS_CLUSTER }} \
          --set serviceAccount.create=false \
          --set serviceAccount.name=aws-load-balancer-controller || \
          echo "ALB Controller installation failed, continuing without it"
    
    - name: Get service URLs
      run: |
        echo "Waiting for LoadBalancer IPs..."
        sleep 120
        
        echo "ðŸš€ Service URLs:"
        
        # Get LoadBalancer hostnames
        IRIS_LB=$(kubectl get svc iris-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || echo "pending")
        STREAMLIT_LB=$(kubectl get svc streamlit -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || echo "pending")
        GRAFANA_LB=$(kubectl get svc grafana -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || echo "pending")
        PROMETHEUS_LB=$(kubectl get svc prometheus -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || echo "pending")
        
        echo "Iris API: http://${IRIS_LB}"
        echo "Streamlit: http://${STREAMLIT_LB}:8501"
        echo "Grafana: http://${GRAFANA_LB}:3000 (admin/admin123)"
        echo "Prometheus: http://${PROMETHEUS_LB}:9090"
        
        # Save URLs as outputs
        echo "IRIS_URL=http://${IRIS_LB}" >> $GITHUB_ENV
        echo "STREAMLIT_URL=http://${STREAMLIT_LB}:8501" >> $GITHUB_ENV
        echo "GRAFANA_URL=http://${GRAFANA_LB}:3000" >> $GITHUB_ENV
        echo "PROMETHEUS_URL=http://${PROMETHEUS_LB}:9090" >> $GITHUB_ENV
    
    - name: Test deployment
      run: |
        # Wait a bit more for services to be ready
        sleep 60
        
        # Test the API endpoint
        IRIS_LB=$(kubectl get svc iris-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        
        if [ "$IRIS_LB" != "" ] && [ "$IRIS_LB" != "pending" ]; then
          echo "Testing API endpoint..."
          curl -X POST "http://${IRIS_LB}/predict_single" \
            -H "Content-Type: application/json" \
            -d '{"sepal_length": 5.1, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2}' \
            || echo "API test failed, but continuing..."
        else
          echo "LoadBalancer not ready yet"
        fi
        
        echo "ðŸŽ‰ Deployment completed successfully!"

  cleanup:
    needs: [infrastructure, build-and-deploy]
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.destroy_infrastructure == 'true' }}
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.6.0
    
    - name: Terraform Destroy
      run: |
        cd terraform-scripts
        terraform init
        terraform destroy -auto-approve
        
        echo "ðŸ§¹ Infrastructure destroyed"
