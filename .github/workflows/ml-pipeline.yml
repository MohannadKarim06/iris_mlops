name: Deploy MLOps Pipeline - Minimal

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  AWS_REGION: eu-north-1
  EKS_CLUSTER: iris-mlops-cluster
  ECR_REPOSITORY: iris-bentoml

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.8'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Initialize DVC
      run: |
        dvc init --no-scm || echo "DVC is already initialized"

    - name: Run ML Pipeline 
      run: |
        dvc repro
    
    - name: Build BentoML Service
      run: |
        # Build models first
        python scripts/build_bento.py
        
        # Navigate to bentoml directory
        cd bentoml
        
        # Copy required files
        cp ../requirements.txt .
        mkdir -p models
        cp -r ../models/* models/
        
        # Build only (no containerize)
        echo "Building BentoML service..."
        bentoml build
        
        cd ..

    - name: Build Custom Docker Image
      run: |
        # Copy Dockerfile to bentoml directory
        cp Dockerfile bentoml/
        
        # Build Docker image using our custom Dockerfile
        cd bentoml
        docker build -t iris_classifier_service:latest .
        
        # Tag the image for ECR
        docker tag iris_classifier_service:latest iris_classifier_service:${{ github.sha }}
        
        echo "Docker image built successfully"
        docker images | grep iris_classifier_service

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Login to ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1
    
    - name: Build and push Docker image
      run: |
        # Get ECR repository URI dynamically
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        ECR_URI="${ACCOUNT_ID}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ env.ECR_REPOSITORY }}"
        
        docker tag iris_classifier_service:latest $ECR_URI:${{ github.sha }}
        docker tag iris_classifier_service:latest $ECR_URI:latest
        
        # Push to ECR
        docker push $ECR_URI:${{ github.sha }}
        docker push $ECR_URI:latest
        
        echo "ECR_URI=$ECR_URI" >> $GITHUB_ENV
        echo "IMAGE_TAG=${{ github.sha }}" >> $GITHUB_ENV
    
    - name: Install and Configure kubectl
      run: |
        # Install kubectl
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/
        
        # Configure kubectl
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER }}
        
        # Test connection
        kubectl get nodes
        
        echo "‚úÖ kubectl configured successfully"
    
    - name: Deploy to EKS (Iris Service Only)
      run: |
        # Update image in deployment
        export ECR_IMAGE="${{ env.ECR_URI }}:${{ env.IMAGE_TAG }}"
        export ECR_REGISTRY="$(aws sts get-caller-identity --query Account --output text).dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"
        export IMAGE_TAG="${{ env.IMAGE_TAG }}"
        
        # Deploy ONLY Iris service
        envsubst < k8s/iris-service.yaml | kubectl apply -f -
        
        # COMMENTED OUT - Streamlit UI (can be enabled later)
        # kubectl apply -f k8s/streamlit.yaml
        
        # COMMENTED OUT - Other services for portfolio reference
        # envsubst < k8s/mlflow.yaml | kubectl apply -f -
        # kubectl apply -f k8s/prometheus.yaml
        # kubectl apply -f k8s/grafana.yaml
        
        # Wait for ONLY the Iris service deployment
        kubectl rollout status deployment/iris-service --timeout=600s
        
        echo "‚úÖ Iris service deployment completed"
    
    - name: Get service information
      run: |
        echo "üöÄ Deployment Status (Iris Service Only):"
        echo "========================================="
        
        # Show deployment status
        kubectl get deployments
        echo ""
        
        # Show services
        kubectl get services
        echo ""
        
        # Show pods
        kubectl get pods
        echo ""
        
        echo "üîç Service URLs (may take a few minutes to be ready):"
        echo "=================================================="
        
        # Function to get LoadBalancer URL
        get_lb_url() {
          local service_name=$1
          local hostname=$(kubectl get svc $service_name -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "pending")
          if [ "$hostname" != "pending" ] && [ "$hostname" != "" ]; then
            echo "http://${hostname}"
          else
            echo "Pending... (check again in a few minutes)"
          fi
        }
        
        echo "Iris API:    $(get_lb_url iris-service)"
        echo ""
        echo "# AVAILABLE BUT NOT DEPLOYED (for portfolio reference):"
        echo "# Streamlit UI: Available in k8s/streamlit.yaml"
        echo "# Grafana Dashboard: Available in k8s/grafana.yaml"
        echo "# Prometheus Metrics: Available in k8s/prometheus.yaml"
        echo "# MLflow Tracking: Available in k8s/mlflow.yaml"
    
    - name: Test API endpoint
      run: |
        echo "‚è≥ Waiting for Iris service to be ready..."
        sleep 120
        
        # Get the LoadBalancer hostname
        IRIS_LB=$(kubectl get svc iris-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null)
        
        if [ "$IRIS_LB" != "" ] && [ "$IRIS_LB" != "null" ]; then
          echo "üß™ Testing API endpoint: http://${IRIS_LB}"
          
          # Test health endpoint
          echo "Testing health endpoint..."
          curl -f "http://${IRIS_LB}/health" && echo "" || echo "Health check failed"
          
          # Test prediction endpoint
          echo "Testing prediction endpoint..."
          curl -X POST "http://${IRIS_LB}/predict_single" \
            -H "Content-Type: application/json" \
            -d '{"sepal_length": 5.1, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2}' \
            && echo "" || echo "Prediction test failed"
            
          echo "‚úÖ API tests completed"
          echo ""
          echo "üéØ API Documentation:"
          echo "GET  http://${IRIS_LB}/health"
          echo "POST http://${IRIS_LB}/predict_single"
          echo "POST http://${IRIS_LB}/predict_batch"
          
        else
          echo "‚ö†Ô∏è  LoadBalancer not ready yet. Check the service URL manually in a few minutes."
        fi
        
        echo ""
        echo "üéâ Iris ML API deployment completed successfully!"
        echo "üìä Your ML API is now live and ready to serve predictions!"
        echo "üí° This is a minimal deployment focusing on the core ML service."
        echo "üí° Full stack (UI, monitoring, etc.) available in codebase for portfolio showcase."
